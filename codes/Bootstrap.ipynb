{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "import numpy as np\n",
    "from sklearn import datasets\n",
    "import matplotlib.pyplot as plt \n",
    "from sklearn.cluster import KMeans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "warnings.filterwarnings('ignore')\n",
    "np.set_printoptions(suppress=True, precision=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of entities: 91 , number of features: 5\n"
     ]
    }
   ],
   "source": [
    "data = np.loadtxt(\"../data/rin.dat\")  #  data matrix\n",
    "\n",
    "print(\"number of entities:\", data.shape[0], \", number of features:\", data.shape[1])\n",
    "\n",
    "with open(\"../data/namrin\", 'r') as fp:  # load names as list of string\n",
    "    names_ = fp.readlines()\n",
    "\n",
    "with open(\"../data/varrin\", 'r') as fp:  # load features names as list of string\n",
    "    features_ = fp.readlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def standardizer(x):\n",
    "    \n",
    "    \"\"\"\n",
    "        standardize entity-to-feature data matrix by \n",
    "          applying Z-scoring and Range standardization methods\n",
    "        \n",
    "        Arguments: \n",
    "            x, numpy array, entity-to-feature data matrix\n",
    "        \n",
    "        Returns:\n",
    "            Z-scored and Range standardized data matrices\n",
    "    \"\"\"\n",
    "    \n",
    "    x_ave = np.mean(x, axis=0)\n",
    "    x_rng = np.ptp(x, axis=0)\n",
    "    x_std = np.std(x, axis=0)\n",
    "    x_zscr_std = np.divide(np.subtract(x, x_ave), x_std)   # Z-scoring standardization\n",
    "    x_rng_std = np.divide(np.subtract(x, x_ave), x_rng)  # Range standardization \n",
    "    return x_zscr_std, x_rng_std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_kmeans(x_org, n_clusters, n_repeats, std_method='r'):\n",
    "\n",
    "\n",
    "    \"\"\"\n",
    "        Calls Kmeans algorithm from Sklearn library.\n",
    "        Parameters:\n",
    "            x, a numpy arrary, entity-to-feature matrix,\n",
    "            n_clusters, int, number of clusters to detect,\n",
    "            n_repeats, int, number of repeats for different initilization\n",
    "        Return:\n",
    "            centroids, clusters labels over\n",
    "    \"\"\"\n",
    "    \n",
    "    tmp_inertia = 0\n",
    "    clusters, best_clusters = {}, {}\n",
    "    indices, best_indices = {}, {}\n",
    "    cluster_means, best_cluster_means = {}, {}\n",
    "    differences, best_differences = {}, {}\n",
    "    rel_differences, best_rel_differences = {}, {}\n",
    "    inertia, best_inertia = {}, {}\n",
    "    g_mean = np.mean(x_org, axis=0)\n",
    "    \n",
    "    x_zscr_std, x_rng_std = standardizer(x=x_org)\n",
    "        \n",
    "#     x = x_org\n",
    "    \n",
    "    for i in range(n_repeats):\n",
    "        clusters[i] = {}\n",
    "        cluster_means[i] = {}\n",
    "        differences[i] = {}\n",
    "        rel_differences[i] = {}\n",
    "        indices[i] = {}\n",
    "        inertia[i] = {}\n",
    "        \n",
    "        # instantiate KMeans Alg. object\n",
    "        km = KMeans(n_clusters=n_clusters, init='random', n_init=1, max_iter=500,\n",
    "                    tol=1e-4, random_state=i, algorithm='full', )  # verbose=1\n",
    "        if std_method.lower() == 'r' or \\\n",
    "        std_method.lower() == 'rng' or \\\n",
    "        std_method.lower() == 'range':\n",
    "            km.fit(x_rng_std)  # Compute k-means by calling fit method \n",
    "            \n",
    "        else:\n",
    "            km.fit(x_zscr_std)  # Compute k-means by calling fit method \n",
    "        \n",
    "        # Store the computation results per each initilization\n",
    "        for k in range(n_clusters):\n",
    "            clusters[i][k] = x_org[np.where(km.labels_==k)]\n",
    "            indices[i][k] = np.where(km.labels_==k)[0]\n",
    "            \n",
    "        inertia[i] = km.inertia_\n",
    "        \n",
    "        for k in range(n_clusters):\n",
    "            cluster_means[i][k] = np.mean(clusters[i][k], axis=0)    \n",
    "            differences[i][k] = np.subtract(cluster_means[i][k], g_mean)\n",
    "            rel_differences[i][k] = 100*(np.divide(\n",
    "                np.subtract(cluster_means[i][k], g_mean), g_mean)\n",
    "                                        )\n",
    "        # to chose the best clustering results regarding the inertia\n",
    "        if i == 0 :\n",
    "            tmp_inertia = km.inertia_\n",
    "            delta = 0\n",
    "        if i != 0:\n",
    "            delta = tmp_inertia - km.inertia_\n",
    "        if delta >= 0:\n",
    "            tmp_inertia = km.inertia_    \n",
    "            for k in range(n_clusters):\n",
    "                best_clusters[k] = x_org[np.where(km.labels_==k)]\n",
    "                best_indices[k] = np.where(km.labels_==k)[0]\n",
    "            for k in range(n_clusters):\n",
    "                best_cluster_means[k] = np.mean(best_clusters[k], axis=0)\n",
    "                best_differences[k] = np.subtract(best_cluster_means[k], g_mean)\n",
    "                best_rel_differences[k] = 100*(np.divide(\n",
    "                    np.subtract(best_cluster_means[k], g_mean), g_mean)\n",
    "                                              )\n",
    "            best_inertia = km.inertia_\n",
    "    \n",
    "    return  clusters, best_clusters, indices, \\\n",
    "best_indices, cluster_means, best_cluster_means, \\\n",
    "differences, rel_differences, best_differences, \\\n",
    "best_rel_differences , inertia, best_inertia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def demonstrate_best_results(x, features, clusters, indices,\n",
    "                             cluster_means, differences, rel_differences):\n",
    "    for cluster, result in clusters.items():\n",
    "        print(str(cluster+1), \"\\t #\",\n",
    "              len(indices[cluster] ), \n",
    "              \"\\t\", cluster_means[cluster])\n",
    "    print(\"S\", \"\\t #\", x.shape[0], \"\\t\",\n",
    "          np.mean(x, axis=0))\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_clusters =  9\n",
    "n_repeats = 10\n",
    "clusters_1, best_clusters_1, indices_1, best_indices_1,\\\n",
    "cluster_means_1, best_cluster_means_1,\\\n",
    "differences_1, rel_differences_1, \\\n",
    "best_differences_1, best_rel_differences_1, \\\n",
    "inertia_1, best_intertia_1 = apply_kmeans(x_org=data, \n",
    "                                          n_clusters=n_clusters,\n",
    "                                          n_repeats=n_repeats, \n",
    "                                          std_method='z')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 \t # 2 \t [191.75  169.856  22.88  999.787  72.636]\n",
      "2 \t # 6 \t [296.576 280.274  16.275 899.14  423.349]\n",
      "3 \t # 22 \t [235.869 222.206  13.694 796.813 206.835]\n",
      "4 \t # 3 \t [97.154 90.165  6.99  44.633 97.967]\n",
      "5 \t # 8 \t [184.584 173.772  10.798 970.122 264.067]\n",
      "6 \t # 1 \t [ 339.586  290.917   48.688 1494.369  609.941]\n",
      "7 \t # 12 \t [144.715 136.715   7.983 717.38  135.421]\n",
      "8 \t # 10 \t [ 66.644  62.352   4.266 669.735  61.791]\n",
      "9 \t # 27 \t [191.877 180.306  11.576 711.05  151.047]\n",
      "S \t # 91 \t [187.291 175.757  11.557 756.239 182.125]\n"
     ]
    }
   ],
   "source": [
    "features = [feature.strip().split(\",\")[0] for feature in features_]\n",
    "\n",
    "demonstrate_best_results(x=data, features=features,\n",
    "                         clusters=best_clusters_1,\n",
    "                         indices=best_indices_1, \n",
    "                         cluster_means=best_cluster_means_1, \n",
    "                         differences=best_differences_1, \n",
    "                         rel_differences=best_rel_differences_1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To Select a feature and two clusters\n",
    "We select feature number 0, 1st column, clusters number 5 and 9.\n",
    "\n",
    "We are going to validate the mean of feature 0\n",
    "\n",
    "And compare within cluster means C5 and C9\n",
    "\n",
    "And compare C9 and the grand mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_n = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_confidence(resampled_means):\n",
    "    \n",
    "    \"\"\"\n",
    "        Compute the confidence interval\n",
    "        Arguments: \n",
    "            resampled_means data, numpy array.\n",
    "        Returns:\n",
    "            bootstrap means, bootstrap std, and pivotal and non pivotal boundries\n",
    "    \"\"\"\n",
    "    \n",
    "    # pivotal method:\n",
    "    boots_mean = np.mean(resampled_means)\n",
    "    boots_std = np.std(resampled_means)\n",
    "    \n",
    "    \n",
    "    lbp = boots_mean - 1.96*boots_std  # left bound pivotal\n",
    "    rbp = boots_mean + 1.96*boots_std  # right bound pivotal\n",
    "\n",
    "    # Non-pivotal:\n",
    "    lower_bound_index = int((len(resampled_means))*.025)\n",
    "    higher_bound_index = int((len(resampled_means))*.975)\n",
    "    resampled_mean_sorted = sorted(resampled_means,)\n",
    "\n",
    "    lbn = resampled_mean_sorted[lower_bound_index]  # left bound non pivotal\n",
    "    rbn = resampled_mean_sorted[higher_bound_index]  # right bound non pivotal\n",
    "    \n",
    "    return boots_mean, boots_std, lbp, rbp, lbn, rbn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bootstrapping(x, x_idx_1, x_idx_2, n_resample, n_bootstrap):\n",
    "    \n",
    "    \"\"\"\n",
    "        x, a 1-D array, representing the random samples.\n",
    "        x_idx, a 1-D array, representing the random samples indices:\n",
    "            e.g 1st cluster indices (membership vector) or\n",
    "            a range from 0 to number of random samples.\n",
    "        n_resample, an int., representing the random sampling size.\n",
    "        n_bootstrap, an int, representing the number of \n",
    "            repeats in the bootstrapping procedure.\n",
    "\n",
    "        Returns x_resampled_means, x_resampled_stds,\n",
    "                boots_mean, boots_std,\n",
    "                lbp, rbp, lbn, rbn, \n",
    "        where:\n",
    "            x_resampled_means: list of means of resampled data(x) of the length n_resample;\n",
    "            x_resampled_stds: list of standard deviations of resampled data(x);\n",
    "                of the length n_resample,\n",
    "            boots_mean: floating number, representing bootstrap mean --i.e mean of means)\n",
    "            boots_std: floating number, representing bootstrap std --i.e std of stds.\n",
    "    \"\"\"\n",
    "\n",
    "    np.random.seed(43)  # for the sake of reproducibility\n",
    "    x_resampled_means, x_resampled_stds = [], []  # grand mean\n",
    "    x_resampled_means_1, x_resampled_stds_1 = [], []  # 1st subset \n",
    "    x_resampled_means_2, x_resampled_stds_2 = [], []  # 2nd subset\n",
    "\n",
    "    for _ in range(n_bootstrap):\n",
    "        \n",
    "        # Grand mean:\n",
    "        list_to_choose = range(0, n_resample, 1)\n",
    "        resampled_idx = np.random.choice(list_to_choose,\n",
    "                                         size=n_resample, \n",
    "                                         replace=True,)\n",
    "        \n",
    "        x_resampled = x[resampled_idx]\n",
    "        x_resampled_means.append(np.mean(x_resampled))\n",
    "        x_resampled_stds.append(np.std(x_resampled))  # /np.sqrt(len(x)))\n",
    "        \n",
    "        # 1st subset:\n",
    "        idx_1 = [i for i in resampled_idx if i in x_idx_1]\n",
    "        x_resampled_1 = x[idx_1]\n",
    "        x_resampled_means_1.append(np.mean(x_resampled_1))\n",
    "        x_resampled_stds_1.append(np.std(x_resampled_1))  # /np.sqrt(len(x)))\n",
    "        \n",
    "        # 2nd subset:\n",
    "        idx_2 = [i for i in resampled_idx if i in x_idx_2]\n",
    "        x_resampled_2 = x[idx_2]\n",
    "        x_resampled_means_2.append(np.mean(x_resampled_2))\n",
    "        x_resampled_stds_2.append(np.std(x_resampled_2))  # /np.sqrt(len(x)))\n",
    "        \n",
    "    x_resampled_means = np.asarray(x_resampled_means)\n",
    "    x_resampled_means_1 = np.asarray(x_resampled_means_1)\n",
    "    x_resampled_means_2 = np.asarray(x_resampled_means_2)\n",
    "    \n",
    "    # Grand mean:\n",
    "    boots_mean, boots_std, lbp, rbp, lbn, rbn = compute_confidence(\n",
    "        resampled_means=x_resampled_means)\n",
    "    \n",
    "    # Subtraction of 1st cluster from grand mean:\n",
    "    d1g = np.subtract(x_resampled_means_1, x_resampled_means)\n",
    "    boots_mean_1g, boots_std_1g, lbp_1g, rbp_1g, lbn_1g, rbn_1g = compute_confidence(\n",
    "        resampled_means=d1g)\n",
    "    \n",
    "    # Subtraction of 1st cluster from 2nd cluster:\n",
    "    d12 = np.subtract(x_resampled_means_1, x_resampled_means_2)\n",
    "    boots_mean_12, boots_std_12, lbp_12, rbp_12, lbn_12, rbn_12 = compute_confidence(\n",
    "        resampled_means=d12)\n",
    "    \n",
    "    # x_resampled_means, x_resampled_stds, boots_mean, boots_std, lbp, rbp, lbn, rbn\n",
    "    \n",
    "    return ((lbp, rbp, lbn, rbn), \n",
    "            (lbp_1g, rbp_1g, lbn_1g, rbn_1g), \n",
    "            (lbp_12, rbp_12, lbn_12, rbn_12))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_resample = data.shape[0]\n",
    "n_bootstrap = 5000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "((lbp, rbp, lbn, rbn), \\\n",
    " (lbp_1g, rbp_1g, lbn_1g, rbn_1g), \\\n",
    " (lbp_12, rbp_12, lbn_12, rbn_12)) = bootstrapping(x=data[:, feature_n],\n",
    "                                                   x_idx_1=best_indices_1[4],\n",
    "                                                   x_idx_2=best_indices_1[8],\n",
    "                                                   n_resample=n_resample,\n",
    "                                                   n_bootstrap=n_bootstrap)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Presentation\n",
    "\n",
    "##### 5000 trials means"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t \t Left Bound \t \t  Right Bound \n",
      "Pivotal    : 173.85886641735394 \t 200.56416418923945 \n",
      "Nonpivotal : 173.91437362637365 rbn\t 200.4796923076923\n"
     ]
    }
   ],
   "source": [
    "print(\"\\t \\t Left Bound \\t \\t  Right Bound \")\n",
    "print(\"Pivotal    :\", lbp,\n",
    "      \"\\t\", rbp, \n",
    "      \"\\n\"\n",
    "      \"Nonpivotal :\", lbn, \n",
    "      \"rbn\\t\", rbn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### subtraction of first subset from grand mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t \t Left Bound \t \t  Right Bound \n",
      "Pivotal    : -21.67231900602535 \t 16.393458466086546 \n",
      "Nonpivotal : -22.057054945055 rbn\t 15.984296703296735\n"
     ]
    }
   ],
   "source": [
    "print(\"\\t \\t Left Bound \\t \\t  Right Bound \")\n",
    "print(\"Pivotal    :\", lbp_1g,\n",
    "      \"\\t\", rbp_1g, \n",
    "      \"\\n\"\n",
    "      \"Nonpivotal :\", lbn_1g, \n",
    "      \"rbn\\t\", rbn_1g)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### subtraction of first subset from  second subset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t \t Left Bound \t \t  Right Bound \n",
      "Pivotal    : -22.930068781767716 \t 8.349173721077575 \n",
      "Nonpivotal : -23.057066666666685 rbn\t 8.420068376068343\n"
     ]
    }
   ],
   "source": [
    "print(\"\\t \\t Left Bound \\t \\t  Right Bound \")\n",
    "print(\"Pivotal    :\", lbp_12,\n",
    "      \"\\t\", rbp_12, \n",
    "      \"\\n\"\n",
    "      \"Nonpivotal :\", lbn_12, \n",
    "      \"rbn\\t\", rbn_12)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The mean of one cluster, for the aformentioned feature, is not greater than another."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
